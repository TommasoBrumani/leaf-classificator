{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Final_Submission.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mETCSLw0oIyq",
        "t6iQrCQdsZ6Y",
        "YCp3kukjwQ67",
        "kfgrx0GywgKA"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D27aLYM3Z3t"
      },
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZIGU9x1mlbK"
      },
      "source": [
        "## Colab Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpq8YSQIpmGV"
      },
      "source": [
        "In order to maximize our experiments we made use both of Google Colab, Kaggle and our own machines for the training of our various models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk48xveXvFB5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ounSeL-Hviob"
      },
      "source": [
        "%cd /gdrive/MyDrive/Colab \\Notebooks/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk4K518epYLa"
      },
      "source": [
        "## Python Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOezH8Ukp-pQ"
      },
      "source": [
        "Import statements\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezjqnAwLqMYK"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9mDBfZUqctr"
      },
      "source": [
        "Hyperparameters and constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56HIpCNEqaXH"
      },
      "source": [
        "# Environment parameters\n",
        "model_name = \"Model_MK_XXIX\"\n",
        "seed = 42 + 17\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "# Model parameters\n",
        "epochs = 300\n",
        "patience = 30\n",
        "metrics = [\"categorical_accuracy\"]\n",
        "monitor = \"val_categorical_accuracy\"\n",
        "regularization = 1e-5\n",
        "\n",
        "# Data parameters\n",
        "image_size = (256, 256)\n",
        "color_mode = \"rgb\"\n",
        "input_shape = (256, 256, 3)\n",
        "height_shift_range = 0.3\n",
        "width_shift_range = 0.3\n",
        "rotation_range = 30\n",
        "shear_range = 30\n",
        "zoom_range = 0.3\n",
        "batch_size = 64\n",
        "labels = ['Apple', 'Blueberry', 'Cherry', 'Corn', 'Grape', 'Orange', 'Peach', 'Pepper', 'Potato', 'Raspberry',\n",
        "          'Soybean', 'Squash', 'Strawberry', 'Tomato']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mETCSLw0oIyq"
      },
      "source": [
        "## Dataset Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QuoTKwehwUp"
      },
      "source": [
        "Unzip challenge dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCOiPLdzvy85"
      },
      "source": [
        "!unzip dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbsNujQBoQcu"
      },
      "source": [
        "In order to apply oversampling to balance the dataset we made use of the `splitfolder` python library, which also allowed us to divide the dataset into validation and training sets directly in the data directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdX4MlQPhDrM"
      },
      "source": [
        "!pip install split-folders\n",
        "import splitfolders\n",
        "\n",
        "splitfolders.fixed('training', output=\"data_oversample\", seed=seed, fixed=52, oversample=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h68ZRBPoe9cf"
      },
      "source": [
        "Setting data directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PXRjI2re8G8"
      },
      "source": [
        "dataset_dir = 'data_oversample'\n",
        "training_dir = os.path.join(dataset_dir, 'train')\n",
        "validation_dir = os.path.join(dataset_dir, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6iQrCQdsZ6Y"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmskJpH0wKz3"
      },
      "source": [
        "Setup for augmentation and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rU1TakQS3fI"
      },
      "source": [
        "# Preprocessing function for the transfer learning model that will be used\n",
        "def preprocessing(x):\n",
        "    x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
        "    return x\n",
        "\n",
        "train_data_gen = ImageDataGenerator(preprocessing_function = preprocessing,\n",
        "                                    rotation_range=rotation_range,\n",
        "                                    height_shift_range=height_shift_range,\n",
        "                                    width_shift_range=width_shift_range,\n",
        "                                    zoom_range=zoom_range,\n",
        "                                    shear_range=shear_range,\n",
        "                                    horizontal_flip=True,\n",
        "                                    vertical_flip=True,\n",
        "                                    fill_mode='constant')\n",
        "valid_data_gen = ImageDataGenerator(preprocessing_function = preprocessing,\n",
        "                                    rotation_range=rotation_range,\n",
        "                                    height_shift_range=height_shift_range,\n",
        "                                    width_shift_range=width_shift_range,\n",
        "                                    zoom_range=zoom_range,\n",
        "                                    shear_range=shear_range,\n",
        "                                    horizontal_flip=True,\n",
        "                                    vertical_flip=True,\n",
        "                                    fill_mode='constant')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNixC6ihwGtf"
      },
      "source": [
        "Creation of the data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OztZhs4gv1Q1"
      },
      "source": [
        "train_gen = train_data_gen.flow_from_directory(directory=training_dir,\n",
        "                                               target_size=image_size,\n",
        "                                               color_mode=color_mode,\n",
        "                                               classes=None,\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True,\n",
        "                                               seed=seed)\n",
        "valid_gen = valid_data_gen.flow_from_directory(directory=validation_dir,\n",
        "                                               target_size=image_size,\n",
        "                                               color_mode=color_mode,\n",
        "                                               classes=None,\n",
        "                                               class_mode='categorical',\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=False,\n",
        "                                               seed=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCp3kukjwQ67"
      },
      "source": [
        "## Callbacks and Checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMH2y8EWwwHU"
      },
      "source": [
        "Utility function used to create checkpoints and callbacks for training, taken from the exercise sessions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_LZ1_wgwjLA"
      },
      "source": [
        "def create_folders_and_callbacks(model_name):\n",
        "    exps_dir = os.path.join('models_saved')\n",
        "    if not os.path.exists(exps_dir):\n",
        "        os.makedirs(exps_dir)\n",
        "\n",
        "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "    if not os.path.exists(exp_dir):\n",
        "        os.makedirs(exp_dir)\n",
        "\n",
        "    callbacks = []\n",
        "\n",
        "    # Model checkpoint\n",
        "    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "    if not os.path.exists(ckpt_dir):\n",
        "        os.makedirs(ckpt_dir)\n",
        "\n",
        "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'),\n",
        "                                                       save_weights_only=False,  \n",
        "                                                       save_best_only=False)  \n",
        "    callbacks.append(ckpt_callback)\n",
        "\n",
        "    # Tensorboard\n",
        "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "    if not os.path.exists(tb_dir):\n",
        "        os.makedirs(tb_dir)\n",
        "        \n",
        "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
        "                                                 profile_batch=0,\n",
        "                                                 histogram_freq=1) \n",
        "    callbacks.append(tb_callback)\n",
        "\n",
        "    # Early Stopping\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor=monitor, mode='max', \n",
        "                                                   patience=patience, \n",
        "                                                   restore_best_weights=True, \n",
        "                                                   verbose=1)\n",
        "    callbacks.append(es_callback)\n",
        "\n",
        "    return callbacks\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzyB07Sl0aM6"
      },
      "source": [
        "# **Transfer Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfgrx0GywgKA"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fYr36_QxIhn"
      },
      "source": [
        "Supernet built through transfer learning using EfficientNetB7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI7FtSQ5LeDv"
      },
      "source": [
        "supernet = tfk.applications.EfficientNetB7(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=input_shape,\n",
        "    pooling = \"avg\")\n",
        "\n",
        "supernet.summary()\n",
        "\n",
        "# Supernet locked to be used as feature extractor\n",
        "supernet.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtZ4fgGkxj02"
      },
      "source": [
        "Dense layers added to provide classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muXDzrttxULp"
      },
      "source": [
        "# Declare the layers\n",
        "inputs = tfk.Input(shape=input_shape)\n",
        "\n",
        "x = supernet(inputs)\n",
        "x = tfkl.Dropout(0.3, seed=seed)(x)\n",
        "\n",
        "x = tfkl.Dense(\n",
        "    64, activation='relu', \n",
        "    kernel_initializer = tfk.initializers.GlorotUniform(seed), \n",
        "    kernel_regularizer=tf.keras.regularizers.l2(regularization)\n",
        "    )(x)\n",
        "x = tfkl.Dropout(0.3, seed=seed)(x)\n",
        "\n",
        "outputs = tfkl.Dense(\n",
        "    14, activation='softmax',\n",
        "    kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(x)\n",
        "\n",
        "\n",
        "# Connect input and output \n",
        "model = tfk.Model(inputs=inputs, outputs=outputs, name=model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unWP4wS82qr0"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN64hIfp2srq"
      },
      "source": [
        "model.compile(loss=tfk.losses.CategoricalCrossentropy(), \n",
        "              optimizer=tfk.optimizers.Adam(), \n",
        "              metrics=metrics)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VGIaKgzx-Hf"
      },
      "source": [
        "## Model Fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf6X4M3pzA5y"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lATdirTeyAU7"
      },
      "source": [
        "callbacks = create_folders_and_callbacks(model_name=model_name)\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_gen,\n",
        "    callbacks=callbacks,\n",
        ").history\n",
        "\n",
        "# Save best epoch model\n",
        "model.save(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJwXQ_2_0B0c"
      },
      "source": [
        "Plot the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYX5Qfp1zCiS"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(history['loss'], alpha=.3, color='#4D61E2', linestyle='--')\n",
        "plt.plot(history['val_loss'], label='Transfer Learning', alpha=.8, color='#4D61E2')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Categorical Crossentropy')\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(history['categorical_accuracy'], alpha=.3, color='#4D61E2', linestyle='--')\n",
        "plt.plot(history['val_categorical_accuracy'], label='Transfer Learning', alpha=.8, color='#4D61E2')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ozkmEGo0hdY"
      },
      "source": [
        "# **Fine Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y-RSX7w0JCv"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnGKVoMQ1Zhu"
      },
      "source": [
        "Re-load model after transfer learning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyfiyVBBywwT"
      },
      "source": [
        "ft_model = tfk.models.load_model(model_name)\n",
        "ft_model.summary()\n",
        "\n",
        "# Set all EfficientNet layers to trainable\n",
        "ft_model.get_layer('efficientnetb7').trainable = True\n",
        "for i, layer in enumerate(ft_model.get_layer('efficientnetb7').layers):\n",
        "   print(i, layer.name, layer.trainable)\n",
        "\n",
        "# Freeze all but the last layers\n",
        "for i, layer in enumerate(ft_model.get_layer('efficientnetb7').layers[:795]):\n",
        "    layer.trainable = False\n",
        "for i, layer in enumerate(ft_model.get_layer('efficientnetb7').layers):\n",
        "    print(i, layer.name, layer.trainable)\n",
        "ft_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wqsaXff2b9o"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMBhv23w2dLn"
      },
      "source": [
        "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), \n",
        "                 optimizer=tfk.optimizers.Adam(learning_rate=1e-5), \n",
        "                 metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkONHshr1iTH"
      },
      "source": [
        "## Model Fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea9K3MBR1on9"
      },
      "source": [
        "Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gz_nCi41kx9"
      },
      "source": [
        "callbacks = create_folders_and_callbacks(model_name=model_name)\n",
        "\n",
        "ft_history = ft_model.fit(\n",
        "    x = train_gen,\n",
        "    epochs = epochs,\n",
        "    validation_data = valid_gen,\n",
        "    callbacks = callbacks\n",
        ").history\n",
        "\n",
        "# Save the fine tuned model\n",
        "ft_model.save('FineTuningModel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB5OU3To1sqX"
      },
      "source": [
        "Plot the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LL2yQZ01rI5"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(history['loss'], alpha=.3, color='#4D61E2', linestyle='--')\n",
        "plt.plot(history['val_loss'], label='Transfer Learning', alpha=.8, color='#4D61E2')\n",
        "plt.plot(ft_history['loss'], alpha=.3, color='#da6961', linestyle='--')\n",
        "plt.plot(ft_history['val_loss'], label='Transfer Learning', alpha=.8, color='#da6961')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Categorical Crossentropy')\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(history['categorical_accuracy'], alpha=.3, color='#4D61E2', linestyle='--')\n",
        "plt.plot(history['val_categorical_accuracy'], label='Transfer Learning', alpha=.8, color='#4D61E2')\n",
        "plt.plot(ft_history['categorical_accuracy'], alpha=.3, color='#da6961', linestyle='--')\n",
        "plt.plot(ft_history['val_categorical_accuracy'], label='Transfer Learning', alpha=.8, color='#da6961')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Accuracy')\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}